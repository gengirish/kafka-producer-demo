{
  "prompt": "Implements a  project as a robust Spring Boot Kafka producer service with comprehensive error handling, asynchronous callback mechanisms, and REST API endpoints for message publishing and health checks.\n\n## Implementation Summary\n- **Single-file implementation**: All main components (Spring Boot app, Kafka config, producer service, REST controller) are in `KafkaProducerDemo.java`.\n- **Producer Service**: `KafkaMessageProducerService` (`@Service`) provides asynchronous message publishing using `KafkaTemplate`, with detailed error handling and logging.\n- **Error Handling**: Uses `ListenableFutureCallback` for success/failure, implements retry logic with exponential backoff, and logs all relevant metadata and errors.\n- **Configuration**: Kafka producer settings are externalized in `application.yml` (acks, retries, batch size, idempotence, serializers, etc.).\n- **REST API**: Endpoints for sending string, keyed, and JSON messages, plus health and help endpoints.\n- **Testing**: Comprehensive unit and integration tests for service, controller, configuration, and error scenarios.\n\n## Key Features\n- Asynchronous message publishing with callbacks\n- Retry mechanism with exponential backoff for failures\n- Structured logging (INFO, ERROR, DEBUG) for all scenarios\n- Input validation and null checks\n- REST endpoints for message publishing and health checks\n- Health monitoring via actuator and custom endpoint\n- Utility methods for common message patterns\n",
  "language": "java",
  "ground": "```java\npackage com.example.kafka;\n\nimport org.apache.kafka.clients.producer.ProducerConfig;\nimport org.apache.kafka.clients.producer.ProducerRecord;\nimport org.apache.kafka.clients.producer.RecordMetadata;\nimport org.apache.kafka.common.serialization.StringSerializer;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.beans.factory.annotation.Value;\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Configuration;\nimport org.springframework.http.ResponseEntity;\nimport org.springframework.kafka.core.DefaultKafkaProducerFactory;\nimport org.springframework.kafka.core.KafkaTemplate;\nimport org.springframework.kafka.core.ProducerFactory;\nimport org.springframework.kafka.support.SendResult;\nimport org.springframework.kafka.support.serializer.JsonSerializer;\nimport org.springframework.stereotype.Service;\nimport org.springframework.util.concurrent.ListenableFuture;\nimport org.springframework.util.concurrent.ListenableFutureCallback;\nimport org.springframework.web.bind.annotation.*;\n\nimport javax.annotation.PostConstruct;\nimport java.time.Instant;\nimport java.time.LocalDateTime;\nimport java.time.ZoneId;\nimport java.util.HashMap;\nimport java.util.Map;\nimport java.util.concurrent.CompletableFuture;\nimport java.util.concurrent.TimeUnit;\n\n/**\n * Complete Kafka Producer Demo with Error Handling\n * \n * This single file contains:\n * - Spring Boot Application\n * - Kafka Producer Configuration\n * - Kafka Message Producer Service with comprehensive error handling\n * - REST Controller for testing\n * \n * Features:\n * - Asynchronous message publishing with ListenableFuture callbacks\n * - Comprehensive error handling and retry logic with exponential backoff\n * - Detailed logging for success and failure scenarios\n * - Input validation and null checks\n * - REST API endpoints for testing different message types\n * - Health check functionality\n * \n * Skills Demonstrated:\n * - Apache Kafka concepts (topics, partitions, producers)\n * - Spring for Kafka (KafkaTemplate usage and configuration)\n * - Asynchronous programming with futures and callbacks\n * - Error handling with retry mechanisms\n * - Spring Framework (dependency injection, service layer patterns)\n * - Structured logging with appropriate levels\n * \n * @author Generated Implementation\n * @version 1.0\n */\n@SpringBootApplication\npublic class KafkaProducerDemo {\n\n    public static void main(String[] args) {\n        SpringApplication.run(KafkaProducerDemo.class, args);\n    }\n\n    /**\n     * Kafka Producer Configuration\n     * \n     * This configuration class sets up the Kafka producer with appropriate\n     * serializers and connection properties for optimal performance and reliability.\n     */\n    @Configuration\n    public static class KafkaProducerConfig {\n\n        @Value(\"${spring.kafka.bootstrap-servers:localhost:9092}\")\n        private String bootstrapServers;\n\n        @Value(\"${spring.kafka.producer.acks:all}\")\n        private String acks;\n\n        @Value(\"${spring.kafka.producer.retries:3}\")\n        private Integer retries;\n\n        @Value(\"${spring.kafka.producer.batch-size:16384}\")\n        private Integer batchSize;\n\n        @Value(\"${spring.kafka.producer.linger-ms:1}\")\n        private Integer lingerMs;\n\n        @Value(\"${spring.kafka.producer.buffer-memory:33554432}\")\n        private Integer bufferMemory;\n\n        /**\n         * Producer factory configuration with performance and reliability settings\n         */\n        @Bean\n        public ProducerFactory<String, Object> producerFactory() {\n            Map<String, Object> configProps = new HashMap<>();\n            \n            // Basic connection properties\n            configProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\n            configProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);\n            configProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, JsonSerializer.class);\n            \n            // Performance and reliability properties\n            configProps.put(ProducerConfig.ACKS_CONFIG, acks);\n            configProps.put(ProducerConfig.RETRIES_CONFIG, retries);\n            configProps.put(ProducerConfig.BATCH_SIZE_CONFIG, batchSize);\n            configProps.put(ProducerConfig.LINGER_MS_CONFIG, lingerMs);\n            configProps.put(ProducerConfig.BUFFER_MEMORY_CONFIG, bufferMemory);\n            \n            // Additional reliability settings\n            configProps.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, true);\n            configProps.put(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION, 5);\n            configProps.put(ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG, 30000);\n            configProps.put(ProducerConfig.DELIVERY_TIMEOUT_MS_CONFIG, 120000);\n            \n            return new DefaultKafkaProducerFactory<>(configProps);\n        }\n\n        /**\n         * Kafka template bean for message publishing\n         */\n        @Bean\n        public KafkaTemplate<String, Object> kafkaTemplate() {\n            return new KafkaTemplate<>(producerFactory());\n        }\n    }\n\n    /**\n     * Kafka Message Producer Service\n     * \n     * This service provides robust Kafka message publishing capabilities with comprehensive\n     * error handling, asynchronous processing, and detailed logging. It demonstrates\n     * professional-grade implementation of Spring Kafka integration.\n     * \n     * Core Features:\n     * - Asynchronous message publishing with callbacks\n     * - Comprehensive error handling and logging\n     * - Retry mechanism with exponential backoff\n     * - Input validation and null checks\n     * - Detailed success and failure logging with metadata\n     */\n    @Service\n    public static class KafkaMessageProducerService {\n\n        private static final Logger logger = LoggerFactory.getLogger(KafkaMessageProducerService.class);\n        \n        // Retry configuration constants\n        private static final int MAX_RETRY_ATTEMPTS = 3;\n        private static final long INITIAL_RETRY_DELAY_MS = 1000L;\n        private static final double RETRY_BACKOFF_MULTIPLIER = 2.0;\n        \n        @Autowired\n        private KafkaTemplate<String, Object> kafkaTemplate;\n        \n        /**\n         * Post-construct initialization to verify Kafka template configuration\n         */\n        @PostConstruct\n        public void init() {\n            if (kafkaTemplate == null) {\n                logger.error(\"KafkaTemplate is not properly configured. Please check your Kafka configuration.\");\n                throw new IllegalStateException(\"KafkaTemplate is not available\");\n            }\n            logger.info(\"KafkaMessageProducerService initialized successfully\");\n        }\n        \n        /**\n         * Sends a message to the specified Kafka topic with comprehensive error handling\n         * and asynchronous callback processing.\n         * \n         * This method performs the following operations:\n         * 1. Validates input parameters\n         * 2. Sends message asynchronously using KafkaTemplate\n         * 3. Attaches success/failure callbacks for logging and error handling\n         * 4. Implements retry logic for failed messages\n         * \n         * @param topic The target Kafka topic name (must not be null or empty)\n         * @param key The message key for partitioning (can be null)\n         * @param message The payload object to be sent (must not be null)\n         * \n         * @throws IllegalArgumentException if topic is null/empty or message is null\n         * @throws RuntimeException if Kafka configuration issues are detected\n         */\n        public void sendMessage(String topic, String key, Object message) {\n            // Input validation\n            validateInputParameters(topic, message);\n            \n            logger.debug(\"Preparing to send message to topic: {}, key: {}, message type: {}\", \n                        topic, key, message.getClass().getSimpleName());\n            \n            try {\n                // Send message asynchronously and get ListenableFuture\n                ListenableFuture<SendResult<String, Object>> future = kafkaTemplate.send(topic, key, message);\n                \n                // Add callback for success and failure handling\n                future.addCallback(new MessageSendCallback(topic, key, message, 0));\n                \n            } catch (Exception e) {\n                logger.error(\"Unexpected error occurred while sending message to topic: {}, key: {}, error: {}\", \n                            topic, key, e.getMessage(), e);\n                throw new RuntimeException(\"Failed to send message to Kafka\", e);\n            }\n        }\n        \n        /**\n         * Sends a message with retry capability for failed attempts.\n         * This is an internal method used by the retry mechanism.\n         * \n         * @param topic The target Kafka topic name\n         * @param key The message key for partitioning\n         * @param message The payload object to be sent\n         * @param attemptNumber Current attempt number (0-based)\n         */\n        private void sendMessageWithRetry(String topic, String key, Object message, int attemptNumber) {\n            try {\n                ListenableFuture<SendResult<String, Object>> future = kafkaTemplate.send(topic, key, message);\n                future.addCallback(new MessageSendCallback(topic, key, message, attemptNumber));\n            } catch (Exception e) {\n                logger.error(\"Error on retry attempt {} for topic: {}, key: {}, error: {}\", \n                            attemptNumber + 1, topic, key, e.getMessage(), e);\n                \n                if (attemptNumber < MAX_RETRY_ATTEMPTS - 1) {\n                    scheduleRetry(topic, key, message, attemptNumber + 1);\n                } else {\n                    logger.error(\"All retry attempts exhausted for message to topic: {}, key: {}. Message will be dropped.\", \n                               topic, key);\n                }\n            }\n        }\n        \n        /**\n         * Schedules a retry attempt with exponential backoff delay.\n         * \n         * @param topic The target Kafka topic name\n         * @param key The message key for partitioning\n         * @param message The payload object to be sent\n         * @param attemptNumber Current attempt number\n         */\n        private void scheduleRetry(String topic, String key, Object message, int attemptNumber) {\n            long delayMs = (long) (INITIAL_RETRY_DELAY_MS * Math.pow(RETRY_BACKOFF_MULTIPLIER, attemptNumber));\n            \n            logger.info(\"Scheduling retry attempt {} for topic: {}, key: {} after {}ms delay\", \n                       attemptNumber + 1, topic, key, delayMs);\n            \n            CompletableFuture.delayedExecutor(delayMs, TimeUnit.MILLISECONDS)\n                            .execute(() -> sendMessageWithRetry(topic, key, message, attemptNumber));\n        }\n        \n        /**\n         * Validates input parameters for the sendMessage method.\n         * \n         * @param topic The topic name to validate\n         * @param message The message object to validate\n         * @throws IllegalArgumentException if validation fails\n         */\n        private void validateInputParameters(String topic, Object message) {\n            if (topic == null || topic.trim().isEmpty()) {\n                throw new IllegalArgumentException(\"Topic name cannot be null or empty\");\n            }\n            \n            if (message == null) {\n                throw new IllegalArgumentException(\"Message cannot be null\");\n            }\n            \n            // Additional validation for topic name format (basic check)\n            if (!topic.matches(\"^[a-zA-Z0-9._-]+$\")) {\n                throw new IllegalArgumentException(\"Topic name contains invalid characters. Only alphanumeric, dots, underscores, and hyphens are allowed.\");\n            }\n        }\n        \n        /**\n         * Custom callback implementation for handling message send results.\n         * This inner class provides detailed logging and retry logic for both\n         * successful and failed message deliveries.\n         */\n        private class MessageSendCallback implements ListenableFutureCallback<SendResult<String, Object>> {\n            \n            private final String topic;\n            private final String key;\n            private final Object message;\n            private final int attemptNumber;\n            \n            public MessageSendCallback(String topic, String key, Object message, int attemptNumber) {\n                this.topic = topic;\n                this.key = key;\n                this.message = message;\n                this.attemptNumber = attemptNumber;\n            }\n            \n            /**\n             * Handles successful message delivery.\n             * Logs detailed metadata about the successful send operation.\n             * \n             * @param result The send result containing metadata\n             */\n            @Override\n            public void onSuccess(SendResult<String, Object> result) {\n                if (result != null && result.getRecordMetadata() != null) {\n                    RecordMetadata metadata = result.getRecordMetadata();\n                    ProducerRecord<String, Object> producerRecord = result.getProducerRecord();\n                    \n                    // Convert timestamp to readable format\n                    LocalDateTime timestamp = LocalDateTime.ofInstant(\n                        Instant.ofEpochMilli(metadata.timestamp()), \n                        ZoneId.systemDefault()\n                    );\n                    \n                    logger.info(\"Message sent successfully - Topic: {}, Partition: {}, Offset: {}, \" +\n                               \"Timestamp: {}, Key: {}, Message Type: {}, Attempt: {}\", \n                               metadata.topic(), \n                               metadata.partition(), \n                               metadata.offset(), \n                               timestamp,\n                               key != null ? key : \"null\",\n                               message.getClass().getSimpleName(),\n                               attemptNumber + 1);\n                    \n                    // Debug level logging for additional details\n                    logger.debug(\"Message details - Serialized key size: {} bytes, Serialized value size: {} bytes\",\n                               metadata.serializedKeySize(), \n                               metadata.serializedValueSize());\n                } else {\n                    logger.warn(\"Message sent successfully but result metadata is null - Topic: {}, Key: {}\", \n                               topic, key);\n                }\n            }\n            \n            /**\n             * Handles failed message delivery.\n             * Logs error details and implements retry logic with exponential backoff.\n             * \n             * @param ex The exception that caused the failure\n             */\n            @Override\n            public void onFailure(Throwable ex) {\n                logger.error(\"Failed to send message - Topic: {}, Key: {}, Message Type: {}, \" +\n                            \"Attempt: {}, Error: {}\", \n                            topic, \n                            key != null ? key : \"null\", \n                            message.getClass().getSimpleName(),\n                            attemptNumber + 1,\n                            ex.getMessage(), \n                            ex);\n                \n                // Implement retry logic\n                if (attemptNumber < MAX_RETRY_ATTEMPTS - 1) {\n                    logger.info(\"Initiating retry for failed message - Topic: {}, Key: {}, \" +\n                               \"Next attempt: {}/{}\", \n                               topic, key, attemptNumber + 2, MAX_RETRY_ATTEMPTS);\n                    \n                    scheduleRetry(topic, key, message, attemptNumber + 1);\n                } else {\n                    logger.error(\"All retry attempts ({}) exhausted for message - Topic: {}, Key: {}. \" +\n                               \"Message will be dropped. Consider implementing Dead Letter Queue pattern.\", \n                               MAX_RETRY_ATTEMPTS, topic, key);\n                    \n                    handlePermanentFailure(topic, key, message, ex);\n                }\n            }\n        }\n        \n        /**\n         * Handles permanently failed messages after all retry attempts are exhausted.\n         * This method can be extended to implement Dead Letter Queue pattern or\n         * other failure handling strategies.\n         * \n         * @param topic The target topic\n         * @param key The message key\n         * @param message The failed message\n         * @param lastException The final exception that caused the failure\n         */\n        private void handlePermanentFailure(String topic, String key, Object message, Throwable lastException) {\n            logger.error(\"Handling permanent failure for message - Topic: {}, Key: {}, \" +\n                        \"Final error: {}\", topic, key, lastException.getMessage());\n            \n            // TODO: Implement Dead Letter Queue pattern\n            // TODO: Update failure metrics\n            // TODO: Send alert/notification\n        }\n        \n        /**\n         * Utility method to send a simple string message.\n         * This is a convenience method for common use cases.\n         * \n         * @param topic The target Kafka topic name\n         * @param message The string message to send\n         */\n        public void sendStringMessage(String topic, String message) {\n            sendMessage(topic, null, message);\n        }\n        \n        /**\n         * Utility method to send a message with automatic key generation.\n         * Uses the current timestamp as the key for basic partitioning.\n         * \n         * @param topic The target Kafka topic name\n         * @param message The message object to send\n         */\n        public void sendMessageWithTimestampKey(String topic, Object message) {\n            String timestampKey = String.valueOf(System.currentTimeMillis());\n            sendMessage(topic, timestampKey, message);\n        }\n        \n        /**\n         * Health check method to verify Kafka connectivity.\n         * This method can be used by Spring Boot Actuator health checks.\n         * \n         * @return true if Kafka template is available and configured\n         */\n        public boolean isKafkaAvailable() {\n            try {\n                return kafkaTemplate != null;\n            } catch (Exception e) {\n                logger.warn(\"Kafka health check failed: {}\", e.getMessage());\n                return false;\n            }\n        }\n    }\n\n    /**\n     * REST Controller for testing Kafka message publishing\n     * \n     * This controller provides endpoints to test the KafkaMessageProducerService\n     * with different types of messages and scenarios.\n     */\n    @RestController\n    @RequestMapping(\"/api/kafka\")\n    public static class MessageController {\n\n        @Autowired\n        private KafkaMessageProducerService kafkaProducerService;\n\n        /**\n         * Send a simple string message to a topic\n         */\n        @PostMapping(\"/send/string\")\n        public ResponseEntity<Map<String, Object>> sendStringMessage(\n                @RequestParam String topic,\n                @RequestParam String message) {\n            \n            try {\n                kafkaProducerService.sendStringMessage(topic, message);\n                \n                Map<String, Object> response = new HashMap<>();\n                response.put(\"status\", \"success\");\n                response.put(\"message\", \"Message queued for sending\");\n                response.put(\"topic\", topic);\n                response.put(\"payload\", message);\n                \n                return ResponseEntity.ok(response);\n            } catch (Exception e) {\n                Map<String, Object> response = new HashMap<>();\n                response.put(\"status\", \"error\");\n                response.put(\"message\", e.getMessage());\n                response.put(\"topic\", topic);\n                \n                return ResponseEntity.badRequest().body(response);\n            }\n        }\n\n        /**\n         * Send a message with a specific key to a topic\n         */\n        @PostMapping(\"/send/keyed\")\n        public ResponseEntity<Map<String, Object>> sendKeyedMessage(\n                @RequestParam String topic,\n                @RequestParam String key,\n                @RequestParam String message) {\n            \n            try {\n                kafkaProducerService.sendMessage(topic, key, message);\n                \n                Map<String, Object> response = new HashMap<>();\n                response.put(\"status\", \"success\");\n                response.put(\"message\", \"Message queued for sending\");\n                response.put(\"topic\", topic);\n                response.put(\"key\", key);\n                response.put(\"payload\", message);\n                \n                return ResponseEntity.ok(response);\n            } catch (Exception e) {\n                Map<String, Object> response = new HashMap<>();\n                response.put(\"status\", \"error\");\n                response.put(\"message\", e.getMessage());\n                response.put(\"topic\", topic);\n                response.put(\"key\", key);\n                \n                return ResponseEntity.badRequest().body(response);\n            }\n        }\n\n        /**\n         * Send a JSON object message to a topic\n         */\n        @PostMapping(\"/send/json\")\n        public ResponseEntity<Map<String, Object>> sendJsonMessage(\n                @RequestParam String topic,\n                @RequestBody Map<String, Object> payload) {\n            \n            try {\n                kafkaProducerService.sendMessageWithTimestampKey(topic, payload);\n                \n                Map<String, Object> response = new HashMap<>();\n                response.put(\"status\", \"success\");\n                response.put(\"message\", \"JSON message queued for sending\");\n                response.put(\"topic\", topic);\n                response.put(\"payload\", payload);\n                \n                return ResponseEntity.ok(response);\n            } catch (Exception e) {\n                Map<String, Object> response = new HashMap<>();\n                response.put(\"status\", \"error\");\n                response.put(\"message\", e.getMessage());\n                response.put(\"topic\", topic);\n                \n                return ResponseEntity.badRequest().body(response);\n            }\n        }\n\n        /**\n         * Health check endpoint to verify Kafka connectivity\n         */\n        @GetMapping(\"/health\")\n        public ResponseEntity<Map<String, Object>> healthCheck() {\n            Map<String, Object> response = new HashMap<>();\n            \n            try {\n                boolean isHealthy = kafkaProducerService.isKafkaAvailable();\n                \n                response.put(\"status\", isHealthy ? \"healthy\" : \"unhealthy\");\n                response.put(\"kafka\", isHealthy ? \"connected\" : \"disconnected\");\n                response.put(\"timestamp\", System.currentTimeMillis());\n                \n                return ResponseEntity.ok(response);\n            } catch (Exception e) {\n                response.put(\"status\", \"error\");\n                response.put(\"message\", e.getMessage());\n                response.put(\"timestamp\", System.currentTimeMillis());\n                \n                return ResponseEntity.status(500).body(response);\n            }\n        }\n\n        /**\n         * Get API documentation/help\n         */\n        @GetMapping(\"/help\")\n        public ResponseEntity<Map<String, Object>> getHelp() {\n            Map<String, Object> response = new HashMap<>();\n            Map<String, Object> endpoints = new HashMap<>();\n            \n            endpoints.put(\"POST /api/kafka/send/string\", \n                         \"Send string message. Params: topic, message\");\n            endpoints.put(\"POST /api/kafka/send/keyed\", \n                         \"Send keyed message. Params: topic, key, message\");\n            endpoints.put(\"POST /api/kafka/send/json\", \n                         \"Send JSON message. Params: topic, Body: JSON payload\");\n            endpoints.put(\"GET /api/kafka/health\", \n                         \"Check Kafka producer health\");\n            endpoints.put(\"GET /api/kafka/help\", \n                         \"Show this help message\");\n            \n            response.put(\"service\", \"Kafka Producer Demo API\");\n            response.put(\"version\", \"1.0\");\n            response.put(\"endpoints\", endpoints);\n            \n            return ResponseEntity.ok(response);\n        }\n    }\n}\n\n```",
  "test": "```java\n\npackage com.example.kafka;\n\nimport com.fasterxml.jackson.databind.ObjectMapper;\nimport org.apache.kafka.clients.producer.ProducerRecord;\nimport org.apache.kafka.clients.producer.RecordMetadata;\nimport org.apache.kafka.common.TopicPartition;\nimport org.junit.jupiter.api.BeforeEach;\nimport org.junit.jupiter.api.DisplayName;\nimport org.junit.jupiter.api.Nested;\nimport org.junit.jupiter.api.Test;\nimport org.junit.jupiter.api.extension.ExtendWith;\nimport org.mockito.ArgumentCaptor;\nimport org.mockito.InjectMocks;\nimport org.mockito.Mock;\nimport org.mockito.junit.jupiter.MockitoExtension;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.boot.test.autoconfigure.web.servlet.WebMvcTest;\nimport org.springframework.boot.test.context.SpringBootTest;\nimport org.springframework.boot.test.mock.mockito.MockBean;\nimport org.springframework.http.MediaType;\nimport org.springframework.kafka.core.KafkaTemplate;\nimport org.springframework.kafka.support.SendResult;\nimport org.springframework.test.context.junit.jupiter.SpringJUnitConfig;\nimport org.springframework.test.web.servlet.MockMvc;\nimport org.springframework.util.concurrent.ListenableFuture;\nimport org.springframework.util.concurrent.ListenableFutureCallback;\n\nimport java.util.HashMap;\nimport java.util.Map;\n\nimport static org.junit.jupiter.api.Assertions.*;\nimport static org.mockito.ArgumentMatchers.*;\nimport static org.mockito.Mockito.*;\nimport static org.springframework.test.web.servlet.request.MockMvcRequestBuilders.*;\nimport static org.springframework.test.web.servlet.result.MockMvcResultMatchers.*;\n\n/**\n * Comprehensive test suite for KafkaProducerDemo\n * \n * This test class covers:\n * - Unit tests for KafkaMessageProducerService\n * - Integration tests for MessageController\n * - Error handling scenarios\n * - Validation logic\n * - Callback functionality\n */\n@SpringJUnitConfig\nclass KafkaProducerDemoTest {\n\n    /**\n     * Unit tests for KafkaMessageProducerService\n     */\n    @Nested\n    @ExtendWith(MockitoExtension.class)\n    @DisplayName(\"KafkaMessageProducerService Tests\")\n    class KafkaMessageProducerServiceTest {\n\n        @Mock\n        private KafkaTemplate<String, Object> kafkaTemplate;\n\n        @Mock\n        private ListenableFuture<SendResult<String, Object>> future;\n\n        @Mock\n        private SendResult<String, Object> sendResult;\n\n        // Note: RecordMetadata is final and cannot be mocked directly\n        // We'll create it using constructor or use lenient mocking\n\n        @InjectMocks\n        private KafkaProducerDemo.KafkaMessageProducerService kafkaMessageProducerService;\n\n        @BeforeEach\n        void setUp() {\n            // Setup common mock behavior only when needed\n            lenient().when(kafkaTemplate.send(anyString(), anyString(), any())).thenReturn(future);\n            lenient().when(kafkaTemplate.send(anyString(), isNull(), any())).thenReturn(future);\n            lenient().doNothing().when(future).addCallback(any(ListenableFutureCallback.class));\n        }\n\n        @Test\n        @DisplayName(\"Should send message successfully with valid parameters\")\n        void testSendMessage_Success() {\n            // Given\n            String topic = \"test-topic\";\n            String key = \"test-key\";\n            String message = \"test-message\";\n\n            // When\n            assertDoesNotThrow(() -> {\n                kafkaMessageProducerService.sendMessage(topic, key, message);\n            });\n\n            // Then\n            verify(kafkaTemplate, times(1)).send(topic, key, message);\n            verify(future, times(1)).addCallback(any(ListenableFutureCallback.class));\n        }\n\n        @Test\n        @DisplayName(\"Should throw IllegalArgumentException when topic is null\")\n        void testSendMessage_NullTopic_ThrowsException() {\n            // Given\n            String topic = null;\n            String key = \"test-key\";\n            String message = \"test-message\";\n\n            // When & Then\n            IllegalArgumentException exception = assertThrows(IllegalArgumentException.class, () -> {\n                kafkaMessageProducerService.sendMessage(topic, key, message);\n            });\n\n            assertEquals(\"Topic name cannot be null or empty\", exception.getMessage());\n            verify(kafkaTemplate, never()).send(anyString(), anyString(), any());\n        }\n\n        @Test\n        @DisplayName(\"Should throw IllegalArgumentException when topic is empty\")\n        void testSendMessage_EmptyTopic_ThrowsException() {\n            // Given\n            String topic = \"\";\n            String key = \"test-key\";\n            String message = \"test-message\";\n\n            // When & Then\n            IllegalArgumentException exception = assertThrows(IllegalArgumentException.class, () -> {\n                kafkaMessageProducerService.sendMessage(topic, key, message);\n            });\n\n            assertEquals(\"Topic name cannot be null or empty\", exception.getMessage());\n            verify(kafkaTemplate, never()).send(anyString(), anyString(), any());\n        }\n\n        @Test\n        @DisplayName(\"Should throw IllegalArgumentException when topic contains whitespace only\")\n        void testSendMessage_WhitespaceOnlyTopic_ThrowsException() {\n            // Given\n            String topic = \"   \";\n            String key = \"test-key\";\n            String message = \"test-message\";\n\n            // When & Then\n            IllegalArgumentException exception = assertThrows(IllegalArgumentException.class, () -> {\n                kafkaMessageProducerService.sendMessage(topic, key, message);\n            });\n\n            assertEquals(\"Topic name cannot be null or empty\", exception.getMessage());\n            verify(kafkaTemplate, never()).send(anyString(), anyString(), any());\n        }\n\n        @Test\n        @DisplayName(\"Should throw IllegalArgumentException when message is null\")\n        void testSendMessage_NullMessage_ThrowsException() {\n            // Given\n            String topic = \"test-topic\";\n            String key = \"test-key\";\n            Object message = null;\n\n            // When & Then\n            IllegalArgumentException exception = assertThrows(IllegalArgumentException.class, () -> {\n                kafkaMessageProducerService.sendMessage(topic, key, message);\n            });\n\n            assertEquals(\"Message cannot be null\", exception.getMessage());\n            verify(kafkaTemplate, never()).send(anyString(), anyString(), any());\n        }\n\n        @Test\n        @DisplayName(\"Should throw IllegalArgumentException for invalid topic name characters\")\n        void testSendMessage_InvalidTopicName_ThrowsException() {\n            // Given\n            String topic = \"invalid@topic\";\n            String key = \"test-key\";\n            String message = \"test-message\";\n\n            // When & Then\n            IllegalArgumentException exception = assertThrows(IllegalArgumentException.class, () -> {\n                kafkaMessageProducerService.sendMessage(topic, key, message);\n            });\n\n            assertEquals(\"Topic name contains invalid characters. Only alphanumeric, dots, underscores, and hyphens are allowed.\", \n                        exception.getMessage());\n            verify(kafkaTemplate, never()).send(anyString(), anyString(), any());\n        }\n\n        @Test\n        @DisplayName(\"Should throw RuntimeException when KafkaTemplate throws exception\")\n        void testSendMessage_KafkaTemplateThrowsException() {\n            // Given\n            String topic = \"test-topic\";\n            String key = \"test-key\";\n            String message = \"test-message\";\n            \n            when(kafkaTemplate.send(anyString(), anyString(), any()))\n                .thenThrow(new RuntimeException(\"Kafka connection failed\"));\n\n            // When & Then\n            RuntimeException exception = assertThrows(RuntimeException.class, () -> {\n                kafkaMessageProducerService.sendMessage(topic, key, message);\n            });\n\n            assertEquals(\"Failed to send message to Kafka\", exception.getMessage());\n            verify(kafkaTemplate, times(1)).send(topic, key, message);\n        }\n\n        @Test\n        @DisplayName(\"Should send string message with null key\")\n        void testSendStringMessage() {\n            // Given\n            String topic = \"test-topic\";\n            String message = \"test-message\";\n\n            // When\n            assertDoesNotThrow(() -> {\n                kafkaMessageProducerService.sendStringMessage(topic, message);\n            });\n\n            // Then\n            verify(kafkaTemplate, times(1)).send(topic, null, message);\n            verify(future, times(1)).addCallback(any(ListenableFutureCallback.class));\n        }\n\n        @Test\n        @DisplayName(\"Should send message with timestamp key\")\n        void testSendMessageWithTimestampKey() {\n            // Given\n            String topic = \"test-topic\";\n            String message = \"test-message\";\n\n            // When\n            assertDoesNotThrow(() -> {\n                kafkaMessageProducerService.sendMessageWithTimestampKey(topic, message);\n            });\n\n            // Then\n            ArgumentCaptor<String> keyCaptor = ArgumentCaptor.forClass(String.class);\n            verify(kafkaTemplate, times(1)).send(eq(topic), keyCaptor.capture(), eq(message));\n            \n            // Verify that the key is a timestamp (numeric string)\n            String capturedKey = keyCaptor.getValue();\n            assertNotNull(capturedKey);\n            assertTrue(capturedKey.matches(\"\\\\d+\"));\n            verify(future, times(1)).addCallback(any(ListenableFutureCallback.class));\n        }\n\n        @Test\n        @DisplayName(\"Should return true when Kafka is available\")\n        void testIsKafkaAvailable_WhenTemplateIsAvailable() {\n            // When\n            boolean result = kafkaMessageProducerService.isKafkaAvailable();\n\n            // Then\n            assertTrue(result);\n        }\n\n        @Test\n        @DisplayName(\"Should return false when KafkaTemplate is null\")\n        void testIsKafkaAvailable_WhenTemplateIsNull() {\n            // Given\n            KafkaProducerDemo.KafkaMessageProducerService serviceWithNullTemplate = \n                new KafkaProducerDemo.KafkaMessageProducerService();\n\n            // When\n            boolean result = serviceWithNullTemplate.isKafkaAvailable();\n\n            // Then\n            assertFalse(result);\n        }\n\n        @Test\n        @DisplayName(\"Should accept valid topic names\")\n        void testValidTopicNames() {\n            // Test valid topic names\n            String[] validTopics = {\n                \"test-topic\",\n                \"test_topic\",\n                \"test.topic\",\n                \"TestTopic123\",\n                \"topic-with-numbers-123\",\n                \"topic_with_underscores\",\n                \"topic.with.dots\",\n                \"a\",\n                \"123\",\n                \"topic-123_test.name\"\n            };\n\n            for (String topic : validTopics) {\n                assertDoesNotThrow(() -> {\n                    kafkaMessageProducerService.sendMessage(topic, \"key\", \"message\");\n                }, \"Topic should be valid: \" + topic);\n            }\n        }\n\n        @Test\n        @DisplayName(\"Should reject invalid topic names\")\n        void testInvalidTopicNames() {\n            // Test invalid topic names\n            String[] invalidTopics = {\n                \"topic@invalid\",\n                \"topic with spaces\",\n                \"topic#hash\",\n                \"topic$dollar\",\n                \"topic%percent\",\n                \"topic&ampersand\",\n                \"topic*asterisk\",\n                \"topic+plus\",\n                \"topic=equals\",\n                \"topic[bracket\",\n                \"topic]bracket\",\n                \"topic{brace\",\n                \"topic}brace\",\n                \"topic|pipe\",\n                \"topic\\\\backslash\",\n                \"topic:colon\",\n                \"topic;semicolon\",\n                \"topic\\\"quote\",\n                \"topic'apostrophe\",\n                \"topic<less\",\n                \"topic>greater\",\n                \"topic,comma\",\n                \"topic?question\",\n                \"topic/slash\"\n            };\n\n            for (String topic : invalidTopics) {\n                assertThrows(IllegalArgumentException.class, () -> {\n                    kafkaMessageProducerService.sendMessage(topic, \"key\", \"message\");\n                }, \"Topic should be invalid: \" + topic);\n            }\n        }\n\n        @Test\n        @DisplayName(\"Should handle null key gracefully\")\n        void testSendMessage_NullKey_Success() {\n            // Given\n            String topic = \"test-topic\";\n            String key = null;\n            String message = \"test-message\";\n\n            // When\n            assertDoesNotThrow(() -> {\n                kafkaMessageProducerService.sendMessage(topic, key, message);\n            });\n\n            // Then\n            verify(kafkaTemplate, times(1)).send(topic, key, message);\n            verify(future, times(1)).addCallback(any(ListenableFutureCallback.class));\n        }\n\n        @Test\n        @DisplayName(\"Should handle different message types\")\n        void testSendMessage_DifferentMessageTypes() {\n            // Test with different message types\n            Object[] messages = {\n                \"String message\",\n                123,\n                123.45,\n                true,\n                new HashMap<String, Object>() {{\n                    put(\"key\", \"value\");\n                    put(\"number\", 42);\n                }},\n                new String[]{\"array\", \"of\", \"strings\"}\n            };\n\n            for (Object message : messages) {\n                assertDoesNotThrow(() -> {\n                    kafkaMessageProducerService.sendMessage(\"test-topic\", \"key\", message);\n                }, \"Should handle message type: \" + message.getClass().getSimpleName());\n            }\n\n            verify(kafkaTemplate, times(messages.length)).send(anyString(), anyString(), any());\n        }\n    }\n\n    /**\n     * Integration tests for MessageController\n     */\n    @Nested\n    @WebMvcTest(KafkaProducerDemo.MessageController.class)\n    @DisplayName(\"MessageController Integration Tests\")\n    class MessageControllerTest {\n\n        @Autowired\n        private MockMvc mockMvc;\n\n        @MockBean\n        private KafkaProducerDemo.KafkaMessageProducerService kafkaProducerService;\n\n        @Autowired\n        private ObjectMapper objectMapper;\n\n        @Test\n        @DisplayName(\"Should send string message successfully\")\n        void testSendStringMessage_Success() throws Exception {\n            // Given\n            String topic = \"test-topic\";\n            String message = \"Hello World\";\n\n            doNothing().when(kafkaProducerService).sendStringMessage(topic, message);\n\n            // When & Then\n            mockMvc.perform(post(\"/api/kafka/send/string\")\n                    .param(\"topic\", topic)\n                    .param(\"message\", message)\n                    .contentType(MediaType.APPLICATION_JSON))\n                    .andExpect(status().isOk())\n                    .andExpect(jsonPath(\"$.status\").value(\"success\"))\n                    .andExpect(jsonPath(\"$.message\").value(\"Message queued for sending\"))\n                    .andExpect(jsonPath(\"$.topic\").value(topic))\n                    .andExpect(jsonPath(\"$.payload\").value(message));\n\n            verify(kafkaProducerService, times(1)).sendStringMessage(topic, message);\n        }\n\n        @Test\n        @DisplayName(\"Should handle string message error\")\n        void testSendStringMessage_Error() throws Exception {\n            // Given\n            String topic = \"invalid@topic\";\n            String message = \"Hello World\";\n\n            doThrow(new IllegalArgumentException(\"Invalid topic name\"))\n                .when(kafkaProducerService).sendStringMessage(topic, message);\n\n            // When & Then\n            mockMvc.perform(post(\"/api/kafka/send/string\")\n                    .param(\"topic\", topic)\n                    .param(\"message\", message)\n                    .contentType(MediaType.APPLICATION_JSON))\n                    .andExpect(status().isBadRequest())\n                    .andExpect(jsonPath(\"$.status\").value(\"error\"))\n                    .andExpect(jsonPath(\"$.message\").value(\"Invalid topic name\"))\n                    .andExpect(jsonPath(\"$.topic\").value(topic));\n\n            verify(kafkaProducerService, times(1)).sendStringMessage(topic, message);\n        }\n\n        @Test\n        @DisplayName(\"Should send keyed message successfully\")\n        void testSendKeyedMessage_Success() throws Exception {\n            // Given\n            String topic = \"test-topic\";\n            String key = \"test-key\";\n            String message = \"Hello World\";\n\n            doNothing().when(kafkaProducerService).sendMessage(topic, key, message);\n\n            // When & Then\n            mockMvc.perform(post(\"/api/kafka/send/keyed\")\n                    .param(\"topic\", topic)\n                    .param(\"key\", key)\n                    .param(\"message\", message)\n                    .contentType(MediaType.APPLICATION_JSON))\n                    .andExpect(status().isOk())\n                    .andExpect(jsonPath(\"$.status\").value(\"success\"))\n                    .andExpect(jsonPath(\"$.message\").value(\"Message queued for sending\"))\n                    .andExpect(jsonPath(\"$.topic\").value(topic))\n                    .andExpect(jsonPath(\"$.key\").value(key))\n                    .andExpect(jsonPath(\"$.payload\").value(message));\n\n            verify(kafkaProducerService, times(1)).sendMessage(topic, key, message);\n        }\n\n        @Test\n        @DisplayName(\"Should handle keyed message error\")\n        void testSendKeyedMessage_Error() throws Exception {\n            // Given\n            String topic = \"test-topic\";\n            String key = \"test-key\";\n            String message = \"Hello World\";\n\n            doThrow(new RuntimeException(\"Kafka connection failed\"))\n                .when(kafkaProducerService).sendMessage(topic, key, message);\n\n            // When & Then\n            mockMvc.perform(post(\"/api/kafka/send/keyed\")\n                    .param(\"topic\", topic)\n                    .param(\"key\", key)\n                    .param(\"message\", message)\n                    .contentType(MediaType.APPLICATION_JSON))\n                    .andExpect(status().isBadRequest())\n                    .andExpect(jsonPath(\"$.status\").value(\"error\"))\n                    .andExpect(jsonPath(\"$.message\").value(\"Kafka connection failed\"))\n                    .andExpect(jsonPath(\"$.topic\").value(topic))\n                    .andExpect(jsonPath(\"$.key\").value(key));\n\n            verify(kafkaProducerService, times(1)).sendMessage(topic, key, message);\n        }\n\n        @Test\n        @DisplayName(\"Should send JSON message successfully\")\n        void testSendJsonMessage_Success() throws Exception {\n            // Given\n            String topic = \"test-topic\";\n            Map<String, Object> payload = new HashMap<>();\n            payload.put(\"userId\", 123);\n            payload.put(\"action\", \"login\");\n            payload.put(\"timestamp\", \"2024-01-15T10:30:00Z\");\n\n            doNothing().when(kafkaProducerService).sendMessageWithTimestampKey(eq(topic), any(Map.class));\n\n            // When & Then\n            mockMvc.perform(post(\"/api/kafka/send/json\")\n                    .param(\"topic\", topic)\n                    .contentType(MediaType.APPLICATION_JSON)\n                    .content(objectMapper.writeValueAsString(payload)))\n                    .andExpect(status().isOk())\n                    .andExpect(jsonPath(\"$.status\").value(\"success\"))\n                    .andExpect(jsonPath(\"$.message\").value(\"JSON message queued for sending\"))\n                    .andExpect(jsonPath(\"$.topic\").value(topic))\n                    .andExpect(jsonPath(\"$.payload.userId\").value(123))\n                    .andExpect(jsonPath(\"$.payload.action\").value(\"login\"));\n\n            verify(kafkaProducerService, times(1)).sendMessageWithTimestampKey(eq(topic), any(Map.class));\n        }\n\n        @Test\n        @DisplayName(\"Should handle JSON message error\")\n        void testSendJsonMessage_Error() throws Exception {\n            // Given\n            String topic = \"test-topic\";\n            Map<String, Object> payload = new HashMap<>();\n            payload.put(\"userId\", 123);\n\n            doThrow(new IllegalArgumentException(\"Invalid message format\"))\n                .when(kafkaProducerService).sendMessageWithTimestampKey(eq(topic), any(Map.class));\n\n            // When & Then\n            mockMvc.perform(post(\"/api/kafka/send/json\")\n                    .param(\"topic\", topic)\n                    .contentType(MediaType.APPLICATION_JSON)\n                    .content(objectMapper.writeValueAsString(payload)))\n                    .andExpect(status().isBadRequest())\n                    .andExpect(jsonPath(\"$.status\").value(\"error\"))\n                    .andExpect(jsonPath(\"$.message\").value(\"Invalid message format\"))\n                    .andExpect(jsonPath(\"$.topic\").value(topic));\n\n            verify(kafkaProducerService, times(1)).sendMessageWithTimestampKey(eq(topic), any(Map.class));\n        }\n\n        @Test\n        @DisplayName(\"Should return health check when service is healthy\")\n        void testHealthCheck_Healthy() throws Exception {\n            // Given\n            when(kafkaProducerService.isKafkaAvailable()).thenReturn(true);\n\n            // When & Then\n            mockMvc.perform(get(\"/api/kafka/health\")\n                    .contentType(MediaType.APPLICATION_JSON))\n                    .andExpect(status().isOk())\n                    .andExpect(jsonPath(\"$.status\").value(\"healthy\"))\n                    .andExpect(jsonPath(\"$.kafka\").value(\"connected\"))\n                    .andExpect(jsonPath(\"$.timestamp\").exists());\n\n            verify(kafkaProducerService, times(1)).isKafkaAvailable();\n        }\n\n        @Test\n        @DisplayName(\"Should return health check when service is unhealthy\")\n        void testHealthCheck_Unhealthy() throws Exception {\n            // Given\n            when(kafkaProducerService.isKafkaAvailable()).thenReturn(false);\n\n            // When & Then\n            mockMvc.perform(get(\"/api/kafka/health\")\n                    .contentType(MediaType.APPLICATION_JSON))\n                    .andExpect(status().isOk())\n                    .andExpect(jsonPath(\"$.status\").value(\"unhealthy\"))\n                    .andExpect(jsonPath(\"$.kafka\").value(\"disconnected\"))\n                    .andExpect(jsonPath(\"$.timestamp\").exists());\n\n            verify(kafkaProducerService, times(1)).isKafkaAvailable();\n        }\n\n        @Test\n        @DisplayName(\"Should handle health check error\")\n        void testHealthCheck_Error() throws Exception {\n            // Given\n            when(kafkaProducerService.isKafkaAvailable())\n                .thenThrow(new RuntimeException(\"Health check failed\"));\n\n            // When & Then\n            mockMvc.perform(get(\"/api/kafka/health\")\n                    .contentType(MediaType.APPLICATION_JSON))\n                    .andExpect(status().isInternalServerError())\n                    .andExpect(jsonPath(\"$.status\").value(\"error\"))\n                    .andExpect(jsonPath(\"$.message\").value(\"Health check failed\"))\n                    .andExpect(jsonPath(\"$.timestamp\").exists());\n\n            verify(kafkaProducerService, times(1)).isKafkaAvailable();\n        }\n\n        @Test\n        @DisplayName(\"Should return API help documentation\")\n        void testGetHelp() throws Exception {\n            // When & Then\n            mockMvc.perform(get(\"/api/kafka/help\")\n                    .contentType(MediaType.APPLICATION_JSON))\n                    .andExpect(status().isOk())\n                    .andExpect(jsonPath(\"$.service\").value(\"Kafka Producer Demo API\"))\n                    .andExpect(jsonPath(\"$.version\").value(\"1.0\"))\n                    .andExpect(jsonPath(\"$.endpoints\").exists())\n                    .andExpect(jsonPath(\"$.endpoints['POST /api/kafka/send/string']\").exists())\n                    .andExpect(jsonPath(\"$.endpoints['POST /api/kafka/send/keyed']\").exists())\n                    .andExpect(jsonPath(\"$.endpoints['POST /api/kafka/send/json']\").exists())\n                    .andExpect(jsonPath(\"$.endpoints['GET /api/kafka/health']\").exists())\n                    .andExpect(jsonPath(\"$.endpoints['GET /api/kafka/help']\").exists());\n        }\n\n        @Test\n        @DisplayName(\"Should handle missing required parameters\")\n        void testSendStringMessage_MissingParameters() throws Exception {\n            // When & Then - Missing topic parameter\n            mockMvc.perform(post(\"/api/kafka/send/string\")\n                    .param(\"message\", \"Hello World\")\n                    .contentType(MediaType.APPLICATION_JSON))\n                    .andExpect(status().isBadRequest());\n\n            // When & Then - Missing message parameter\n            mockMvc.perform(post(\"/api/kafka/send/string\")\n                    .param(\"topic\", \"test-topic\")\n                    .contentType(MediaType.APPLICATION_JSON))\n                    .andExpect(status().isBadRequest());\n        }\n\n        @Test\n        @DisplayName(\"Should handle missing required parameters for keyed message\")\n        void testSendKeyedMessage_MissingParameters() throws Exception {\n            // When & Then - Missing key parameter\n            mockMvc.perform(post(\"/api/kafka/send/keyed\")\n                    .param(\"topic\", \"test-topic\")\n                    .param(\"message\", \"Hello World\")\n                    .contentType(MediaType.APPLICATION_JSON))\n                    .andExpect(status().isBadRequest());\n        }\n\n        @Test\n        @DisplayName(\"Should handle empty JSON payload\")\n        void testSendJsonMessage_EmptyPayload() throws Exception {\n            // Given\n            String topic = \"test-topic\";\n            Map<String, Object> emptyPayload = new HashMap<>();\n\n            doNothing().when(kafkaProducerService).sendMessageWithTimestampKey(eq(topic), any(Map.class));\n\n            // When & Then\n            mockMvc.perform(post(\"/api/kafka/send/json\")\n                    .param(\"topic\", topic)\n                    .contentType(MediaType.APPLICATION_JSON)\n                    .content(objectMapper.writeValueAsString(emptyPayload)))\n                    .andExpect(status().isOk())\n                    .andExpect(jsonPath(\"$.status\").value(\"success\"));\n\n            verify(kafkaProducerService, times(1)).sendMessageWithTimestampKey(eq(topic), any(Map.class));\n        }\n    }\n\n    /**\n     * Configuration tests\n     */\n    @Nested\n    @SpringBootTest(classes = KafkaProducerDemo.class)\n    @DisplayName(\"Configuration Tests\")\n    class ConfigurationTest {\n\n        @Autowired\n        private KafkaProducerDemo.KafkaProducerConfig kafkaProducerConfig;\n\n        @Test\n        @DisplayName(\"Should create producer factory bean\")\n        void testProducerFactoryBean() {\n            // When\n            var producerFactory = kafkaProducerConfig.producerFactory();\n\n            // Then\n            assertNotNull(producerFactory);\n            assertTrue(producerFactory instanceof org.springframework.kafka.core.DefaultKafkaProducerFactory);\n        }\n\n        @Test\n        @DisplayName(\"Should create kafka template bean\")\n        void testKafkaTemplateBean() {\n            // When\n            var kafkaTemplate = kafkaProducerConfig.kafkaTemplate();\n\n            // Then\n            assertNotNull(kafkaTemplate);\n            assertTrue(kafkaTemplate instanceof org.springframework.kafka.core.KafkaTemplate);\n        }\n    }\n\n    /**\n     * Application context tests\n     */\n    @Nested\n    @SpringBootTest(classes = KafkaProducerDemo.class)\n    @DisplayName(\"Application Context Tests\")\n    class ApplicationContextTest {\n\n        @Autowired\n        private KafkaProducerDemo.KafkaMessageProducerService kafkaMessageProducerService;\n\n        @Autowired\n        private KafkaProducerDemo.MessageController messageController;\n\n        @Test\n        @DisplayName(\"Should load application context successfully\")\n        void testApplicationContextLoads() {\n            // Then\n            assertNotNull(kafkaMessageProducerService);\n            assertNotNull(messageController);\n        }\n\n        @Test\n        @DisplayName(\"Should have proper service initialization\")\n        void testServiceInitialization() {\n            // Then\n            assertTrue(kafkaMessageProducerService.isKafkaAvailable());\n        }\n    }\n}\n\n\n```",
  "dependencies": "```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n    <parent>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-parent</artifactId>\n        <version>2.7.14</version>\n        <relativePath/>\n    </parent>\n    <groupId>com.example</groupId>\n    <artifactId>kafka-producer-demo</artifactId>\n    <version>0.0.1-SNAPSHOT</version>\n    <name>kafka-producer-demo</name>\n    <description>Kafka Producer with Error Handling Demo</description>\n    <properties>\n        <java.version>11</java.version>\n    </properties>\n    <dependencies>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-web</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.kafka</groupId>\n            <artifactId>spring-kafka</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-actuator</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>com.fasterxml.jackson.core</groupId>\n            <artifactId>jackson-databind</artifactId>\n        </dependency>\n        \n        <!-- Test dependencies -->\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-test</artifactId>\n            <scope>test</scope>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.kafka</groupId>\n            <artifactId>spring-kafka-test</artifactId>\n            <scope>test</scope>\n        </dependency>\n        <dependency>\n            <groupId>org.testcontainers</groupId>\n            <artifactId>junit-jupiter</artifactId>\n            <version>1.19.0</version>\n            <scope>test</scope>\n        </dependency>\n        <dependency>\n            <groupId>org.testcontainers</groupId>\n            <artifactId>kafka</artifactId>\n            <version>1.19.0</version>\n            <scope>test</scope>\n        </dependency>\n    </dependencies>\n\n    <build>\n        <plugins>\n            <plugin>\n                <groupId>org.springframework.boot</groupId>\n                <artifactId>spring-boot-maven-plugin</artifactId>\n            </plugin>\n        </plugins>\n    </build>\n</project>\n\n\n```",
  "bash": "```bash\n\n#!/bin/bash\n# Shell script to run and validate the Maven project and its test cases\n# Project: kafka-producer-demo\n\nset -e  # Exit on any error\n\n# Color codes for output formatting\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nBLUE='\\033[0;34m'\nNC='\\033[0m' # No Color\n\n# Function to print colored output\nprint_status() {\n    echo -e \"${BLUE}[INFO]${NC} $1\"\n}\n\nprint_success() {\n    echo -e \"${GREEN}[SUCCESS]${NC} $1\"\n}\n\nprint_warning() {\n    echo -e \"${YELLOW}[WARNING]${NC} $1\"\n}\n\nprint_error() {\n    echo -e \"${RED}[ERROR]${NC} $1\"\n}\n\nprint_header() {\n    echo -e \"\\n${BLUE}================================${NC}\"\n    echo -e \"${BLUE} $1${NC}\"\n    echo -e \"${BLUE}================================${NC}\\n\"\n}\n\n# Function to check if Maven is installed\ncheck_maven() {\n    print_status \"Checking Maven installation...\"\n    if ! command -v mvn &> /dev/null; then\n        print_error \"Maven is not installed or not in PATH\"\n        print_error \"Please install Maven and ensure it's in your PATH\"\n        exit 1\n    fi\n    \n    mvn_version=$(mvn -version | head -n 1)\n    print_success \"Maven found: $mvn_version\"\n}\n\n# Function to check Java version\ncheck_java() {\n    print_status \"Checking Java installation...\"\n    if ! command -v java &> /dev/null; then\n        print_error \"Java is not installed or not in PATH\"\n        exit 1\n    fi\n    \n    java_version=$(java -version 2>&1 | head -n 1)\n    print_success \"Java found: $java_version\"\n}\n\n# Function to validate project structure\nvalidate_project_structure() {\n    print_status \"Validating project structure...\"\n    \n    required_files=(\n        \"pom.xml\"\n        \"src/main/java/com/example/kafka/KafkaProducerDemo.java\"\n        \"src/test/java/com/example/kafka/KafkaProducerDemoTest.java\"\n        \"src/test/java/com/example/kafka/KafkaProducerIntegrationTest.java\"\n        \"src/test/resources/application-test.yml\"\n        \"src/main/resources/application.yml\"\n        \"README.md\"\n        \"QUICK_START.md\"\n        \"TEST_DOCUMENTATION.md\"\n        \"docker-compose.yml\"\n    )\n\n    for file in \"${required_files[@]}\"; do\n        if [[ ! -f \"$file\" ]]; then\n            print_error \"Required file missing: $file\"\n            exit 1\n        fi\n    done\n\n    print_success \"Project structure validation passed\"\n}\n\n# Function to clean the project\nclean_project() {\n    print_status \"Cleaning project...\"\n    if mvn clean > /dev/null 2>&1; then\n        print_success \"Project cleaned successfully\"\n    else\n        print_error \"Failed to clean project\"\n        exit 1\n    fi\n}\n\n# Function to compile the project\ncompile_project() {\n    print_status \"Compiling project...\"\n    if mvn compile -q; then\n        print_success \"Project compiled successfully\"\n    else\n        print_error \"Compilation failed\"\n        exit 1\n    fi\n}\n\n# Function to compile test sources\ncompile_tests() {\n    print_status \"Compiling test sources...\"\n    if mvn test-compile -q; then\n        print_success \"Test sources compiled successfully\"\n    else\n        print_error \"Test compilation failed\"\n        exit 1\n    fi\n}\n\n# Function to run tests\nrun_tests() {\n    print_status \"Running tests...\"\n    \n    # Run tests and capture output\n    if mvn test -q > test_output.log 2>&1; then\n        print_success \"All tests passed\"\n\n        # Extract test results from Surefire reports\n        for report in target/surefire-reports/TEST-*.xml; do\n            if [[ -f \"$report\" ]]; then\n                test_count=$(grep -o 'tests=\"[0-9]*\"' \"$report\" | grep -o '[0-9]*')\n                failures=$(grep -o 'failures=\"[0-9]*\"' \"$report\" | grep -o '[0-9]*')\n                errors=$(grep -o 'errors=\"[0-9]*\"' \"$report\" | grep -o '[0-9]*')\n                test_file=$(basename \"$report\" .xml | sed 's/TEST-//')\n                print_success \"Test Results ($test_file): $test_count tests run, $failures failures, $errors errors\"\n            fi\n        done\n    else\n        print_error \"Tests failed\"\n        echo \"Test output:\"\n        cat test_output.log\n        exit 1\n    fi\n}\n\n# Function to validate test coverage\nvalidate_test_coverage() {\n    print_status \"Validating test coverage...\"\n    \n    # Check if test classes exist\n    test_classes=(\n        \"target/test-classes/com/example/kafka/KafkaProducerDemoTest.class\"\n        \"target/test-classes/com/example/kafka/KafkaProducerIntegrationTest.class\"\n    )\n    \n    test_classes_found=0\n    for test_class in \"${test_classes[@]}\"; do\n        if [[ -f \"$test_class\" ]]; then\n            test_classes_found=$((test_classes_found + 1))\n        fi\n    done\n    \n    if [[ $test_classes_found -eq ${#test_classes[@]} ]]; then\n        print_success \"All test classes found and compiled ($test_classes_found/${#test_classes[@]})\"\n    else\n        print_warning \"Some test classes not found ($test_classes_found/${#test_classes[@]} found)\"\n    fi\n\n    # Check if main classes exist\n    main_classes=(\n        \"target/classes/com/example/kafka/KafkaProducerDemo.class\"\n        \"target/classes/com/example/kafka/KafkaProducerDemo\\$KafkaProducerConfig.class\"\n        \"target/classes/com/example/kafka/KafkaProducerDemo\\$KafkaMessageProducerService.class\"\n        \"target/classes/com/example/kafka/KafkaProducerDemo\\$MessageController.class\"\n    )\n    \n    main_classes_found=0\n    for main_class in \"${main_classes[@]}\"; do\n        if [[ -f \"$main_class\" ]]; then\n            main_classes_found=$((main_classes_found + 1))\n        fi\n    done\n    \n    if [[ $main_classes_found -eq ${#main_classes[@]} ]]; then\n        print_success \"All main classes found and compiled ($main_classes_found/${#main_classes[@]})\"\n    else\n        print_error \"Main classes not found ($main_classes_found/${#main_classes[@]} found)\"\n        exit 1\n    fi\n}\n\n# Function to run dependency check\ncheck_dependencies() {\n    print_status \"Checking project dependencies...\"\n    \n    if mvn dependency:resolve -q > /dev/null 2>&1; then\n        print_success \"All dependencies resolved successfully\"\n    else\n        print_error \"Failed to resolve dependencies\"\n        exit 1\n    fi\n}\n\n# Function to validate specific test categories\nvalidate_test_categories() {\n    print_status \"Validating test categories...\"\n\n    categories=(\n        \"KafkaProducerDemoTest\"\n        \"KafkaProducerIntegrationTest\"\n    )\n\n    for category in \"${categories[@]}\"; do\n        if mvn test -Dtest=\"*$category\" -q > /dev/null 2>&1; then\n            print_success \"Test category '$category' passed\"\n        else\n            print_error \"Test category '$category' failed\"\n            exit 1\n        fi\n    done\n}\n\n# Function to validate Kafka producer features\nvalidate_kafka_features() {\n    print_status \"Validating Kafka producer features...\"\n    \n    # Check if main application contains required annotations and configuration\n    app_file=\"src/main/java/com/example/kafka/KafkaProducerDemo.java\"\n    config_file=\"src/main/resources/application.yml\"\n    \n    app_features=(\n        \"@SpringBootApplication\"\n        \"@Service\"\n        \"@RestController\"\n        \"KafkaTemplate\"\n        \"ListenableFuture\"\n        \"ListenableFutureCallback\"\n        \"sendMessage\"\n        \"onSuccess\"\n        \"onFailure\"\n        \"ProducerConfig\"\n        \"JsonSerializer\"\n        \"StringSerializer\"\n    )\n    \n    config_features=(\n        \"spring.kafka.bootstrap-servers\"\n        \"spring.kafka.producer.acks\"\n        \"spring.kafka.producer.retries\"\n        \"spring.kafka.producer.batch-size\"\n        \"spring.kafka.producer.linger-ms\"\n    )\n    \n    print_status \"Checking application features...\"\n    for feature in \"${app_features[@]}\"; do\n        if grep -q \"$feature\" \"$app_file\"; then\n            print_success \"Application feature '$feature' found\"\n        else\n            print_warning \"Application feature '$feature' not found\"\n        fi\n    done\n    \n    print_status \"Checking configuration features...\"\n    for feature in \"${config_features[@]}\"; do\n        if grep -q \"$feature\" \"$config_file\"; then\n            print_success \"Configuration feature '$feature' found\"\n        else\n            print_warning \"Configuration feature '$feature' not found\"\n        fi\n    done\n}\n\n# Function to validate test features\nvalidate_test_features() {\n    print_status \"Validating test features...\"\n    \n    test_file=\"src/test/java/com/example/kafka/KafkaProducerDemoTest.java\"\n    integration_test_file=\"src/test/java/com/example/kafka/KafkaProducerIntegrationTest.java\"\n    \n    test_features=(\n        \"@ExtendWith(MockitoExtension.class)\"\n        \"@Mock\"\n        \"@InjectMocks\"\n        \"@WebMvcTest\"\n        \"@MockBean\"\n        \"@SpringBootTest\"\n        \"MockMvc\"\n        \"verify\"\n        \"when\"\n        \"assertThrows\"\n        \"assertDoesNotThrow\"\n        \"ArgumentCaptor\"\n        \"@DisplayName\"\n        \"@Nested\"\n    )\n    \n    print_status \"Checking test features...\"\n    for feature in \"${test_features[@]}\"; do\n        if grep -q \"$feature\" \"$test_file\" || grep -q \"$feature\" \"$integration_test_file\"; then\n            print_success \"Test feature '$feature' found\"\n        else\n            print_warning \"Test feature '$feature' not found\"\n        fi\n    done\n}\n\n# Function to run integration validation\nrun_integration_validation() {\n    print_status \"Running integration validation...\"\n    \n    # Start the application in background for integration testing\n    print_status \"Starting Spring Boot application for integration testing...\"\n    mvn spring-boot:run > app_output.log 2>&1 &\n    APP_PID=$!\n    \n    # Wait for application to start\n    sleep 20\n    \n    # Check if application is running\n    if kill -0 $APP_PID 2>/dev/null; then\n        print_success \"Application started successfully (PID: $APP_PID)\"\n        \n        # Test Kafka producer endpoints if curl is available\n        if command -v curl &> /dev/null; then\n            print_status \"Testing API help endpoint...\"\n            if curl -s -o /dev/null -w \"%{http_code}\" http://localhost:8080/api/kafka/help | grep -q \"200\"; then\n                print_success \"API help endpoint test passed\"\n            else\n                print_warning \"API help endpoint test failed or returned non-200 status\"\n            fi\n            \n            print_status \"Testing health endpoint...\"\n            if curl -s -o /dev/null -w \"%{http_code}\" http://localhost:8080/api/kafka/health | grep -q \"200\"; then\n                print_success \"Health endpoint test passed\"\n            else\n                print_warning \"Health endpoint test failed or returned non-200 status\"\n            fi\n            \n            print_status \"Testing string message endpoint...\"\n            if curl -s -o /dev/null -w \"%{http_code}\" -X POST \"http://localhost:8080/api/kafka/send/string?topic=test-topic&message=test-message\" | grep -q \"200\"; then\n                print_success \"String message endpoint test passed\"\n            else\n                print_warning \"String message endpoint test failed or returned non-200 status\"\n            fi\n        else\n            print_warning \"curl not available, skipping endpoint tests\"\n        fi\n        \n        # Stop the application\n        print_status \"Stopping application...\"\n        kill $APP_PID 2>/dev/null || true\n        wait $APP_PID 2>/dev/null || true\n        print_success \"Application stopped\"\n    else\n        print_error \"Failed to start application\"\n        exit 1\n    fi\n}\n\n# Function to validate Docker setup\nvalidate_docker_setup() {\n    print_status \"Validating Docker setup...\"\n    \n    if [[ -f \"docker-compose.yml\" ]]; then\n        print_success \"Docker Compose file found\"\n        \n        if command -v docker-compose &> /dev/null || command -v docker &> /dev/null; then\n            print_success \"Docker/Docker Compose available\"\n            \n            # Check if docker-compose file is valid\n            if docker-compose config > /dev/null 2>&1; then\n                print_success \"Docker Compose configuration is valid\"\n            else\n                print_warning \"Docker Compose configuration validation failed\"\n            fi\n        else\n            print_warning \"Docker/Docker Compose not available, skipping Docker validation\"\n        fi\n    else\n        print_warning \"Docker Compose file not found\"\n    fi\n}\n\n# Function to generate project report\ngenerate_report() {\n    print_status \"Generating project report...\"\n    \n    echo \"Project Validation Report\" > validation_report.txt\n    echo \"=========================\" >> validation_report.txt\n    echo \"Date: $(date)\" >> validation_report.txt\n    echo \"Project: kafka-producer-demo\" >> validation_report.txt\n    echo \"\" >> validation_report.txt\n\n    echo \"Maven Version:\" >> validation_report.txt\n    mvn -version >> validation_report.txt 2>&1\n    echo \"\" >> validation_report.txt\n\n    echo \"Java Version:\" >> validation_report.txt\n    java -version >> validation_report.txt 2>&1\n    echo \"\" >> validation_report.txt\n\n    echo \"Dependencies:\" >> validation_report.txt\n    mvn dependency:list -q >> validation_report.txt 2>&1\n    echo \"\" >> validation_report.txt\n\n    echo \"Test Results Summary:\" >> validation_report.txt\n    for report in target/surefire-reports/TEST-*.xml; do\n        if [[ -f \"$report\" ]]; then\n            echo \"Test Results Summary ($(basename \"$report\")):\" >> validation_report.txt\n            grep -E \"(tests=|failures=|errors=|time=)\" \"$report\" >> validation_report.txt\n        fi\n    done\n\n    echo \"\" >> validation_report.txt\n    echo \"Kafka Producer Demo Features Validated:\" >> validation_report.txt\n    echo \"- Spring Boot Application (@SpringBootApplication)\" >> validation_report.txt\n    echo \"- Kafka Producer Service (@Service)\" >> validation_report.txt\n    echo \"- KafkaTemplate Integration with JSON Serialization\" >> validation_report.txt\n    echo \"- Asynchronous Message Publishing with ListenableFuture\" >> validation_report.txt\n    echo \"- Comprehensive Error Handling with Callbacks\" >> validation_report.txt\n    echo \"- Retry Logic with Exponential Backoff\" >> validation_report.txt\n    echo \"- Input Validation and Topic Name Validation\" >> validation_report.txt\n    echo \"- REST API Endpoints for Message Publishing\" >> validation_report.txt\n    echo \"- Health Check and Service Monitoring\" >> validation_report.txt\n    echo \"- Comprehensive Test Suite (Unit, Integration, Mock-based)\" >> validation_report.txt\n    echo \"- Docker Compose Setup for Kafka Development\" >> validation_report.txt\n\n    print_success \"Report generated: validation_report.txt\"\n}\n\n# Function to cleanup temporary files\ncleanup() {\n    print_status \"Cleaning up temporary files...\"\n    rm -f test_output.log app_output.log\n    print_success \"Cleanup completed\"\n}\n\n# Main execution function\nmain() {\n    print_header \"Maven Project Validation Script\"\n    print_status \"Starting validation for kafka-producer-demo project...\"\n\n    # Pre-flight checks\n    check_java\n    check_maven\n    validate_project_structure\n\n    print_header \"Building and Testing Project\"\n\n    # Build and test\n    clean_project\n    check_dependencies\n    compile_project\n    compile_tests\n    validate_test_coverage\n    run_tests\n    validate_test_categories\n\n    print_header \"Kafka Producer Feature Validation\"\n    validate_kafka_features\n    validate_test_features\n\n    print_header \"Docker Setup Validation\"\n    validate_docker_setup\n\n    print_header \"Integration Testing\"\n    run_integration_validation\n\n    print_header \"Generating Report\"\n    generate_report\n\n    print_header \"Validation Complete\"\n    print_success \"All validations passed successfully!\"\n    print_success \"The kafka-producer-demo project is working correctly.\"\n    print_success \"Kafka producer configuration and error handling have been validated.\"\n    print_success \"Comprehensive test suite with 49+ tests is passing.\"\n\n    cleanup\n}\n\n# Trap to ensure cleanup on exit\ntrap cleanup EXIT\n\n# Run main function\nmain \"$@\"\n\n\n```",
  "timeout": 180
}